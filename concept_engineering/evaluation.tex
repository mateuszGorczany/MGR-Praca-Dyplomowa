\subsubsection{Algorithms}
Evaluating the quality of artificial model reconstructions or generations necessitates specialized algorithms. These algorithms must be capable of comparing not only individual pixels, but also the structure and semantics of the images.
\paragraph{L1 norm}\mbox{}\\
The L1 norm is also known as the Manhattan distance or Taxicab norm is the most straightforward method for measuring the distance between vectors, matrices, or tensors. Calculated as the sum of the absolute differences between their components. 
L1 and L2 norms measure pixel-wise differences between generated and real images.
For vectors, the L1 Norm represents the magnitude in a given space. Under this norm, each component of the vector is equally weighted. 

In the case of grey CT scan (1,W,H,D) it is calculated as follows:
\begin{equation}
||x-\hat{x}||_1 = \sum_{i=1}^{W} \sum_{j=1}^{H} \sum_{k=1}^{D} |x_{i,j,k}-\hat{x}_{i,j,k}|
\label{norm-l1}
\end{equation}

\paragraph{L2 norm}\mbox{}\\
L2 norm emphasizes larger deviations, making it sensitive to noise and outliers.
\begin{equation}
||x-\hat{x}||_2 = \sqrt{\sum_{i=1}^{W} \sum_{j=1}^{H} \sum_{k=1}^{D} {(x_{i,j,k}-\hat{x}_{i,j,k})^2}}
\label{norm-l2}
\end{equation}
\paragraph{SSIM - Structural Similarity Metric}\mbox{}\\
SSIM is a metric designed to assess image quality by comparing the structural information between two images. Unlike pixel-wise metrics like L1 or L2, SSIM focuses on perceived changes in structural information, such as luminance, contrast, and spatial correlations, which are crucial for medical images like CT scans.
\begin{equation}
    \hbox{SSIM}(x,y) = \frac{(2\mu_x\mu_y + c_1)(2\sigma_{xy} + c_2)}{(\mu_x^2 + \mu_y^2 + c_1)(\sigma_x^2 + \sigma_y^2 + c_2)}
\end{equation}

\begin{itemize}
    \item $\mu_{x}$ - the pixel sample mean of $x$;  
    \item $\mu_{\hat{x}}$ - the pixel sample mean of $\hat{x}$;  
    \item $\sigma_{x}^{2}$ the variance of $x$;  
    \item $\sigma_{\hat{x}}^{2}$ the variance of $\hat{x}$;  
    \item $\sigma_{x\hat{x}}$ the covariance of $x$ and $\hat{x}$;  
\end{itemize}

\[
c_{1} = (k_{1}L)^{2}, \quad c_{2} = (k_{2}L)^{2}
\]
are two variables to stabilize the division with weak denominator.

Where:
\[
L = 2^{\#\text{bits per pixel}} - 1,
\]
$k_{1} = 0.01$ and $k_{2} = 0.03$ by default.

\paragraph{LPIPS - Learned Perceptual Image Patch Similarity}\mbox{}\\
The objective of LPIPS is to assess the perceptual similarity between two images by utilising deep neural networks that have been trained on human visual preferences.

\paragraph{FID - Frechet Image Distance}\mbox{}\\
The FID score compares the distribution of two datasets (real and generated) by calculating the Fr√©chet distance between multivariate Gaussian distributions, estimated from feature vectors extracted from a pre-trained deep network. The lower the FID score, the more similar the generated images are to the real ones. FVD - Frechet Video Distance.

\paragraph{Human evaluation}
The final quality of generated reconstructions or scans can be evaluated by humans. Especially when it comes to assesing the final quality of generated dataset - specialists from the field of radiology and medicine should be the ones who do it. 