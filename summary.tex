This project assessed the performance of VAE, VQVAE, and VQGAN models for generating synthetic prostate CT scans. The implementation utilized modern GPUs and multi-GPU training methods. Tensorboard and WanDB were employed to monitor the AI model training. The execution environment was set up with cutting-edge technologies, Devbox and Rye, to ease future work. Furthermore, the project was initiated with a template that is widely adopted as a standard in the Data Science community.

 The results obtained allowed us to compare them and select the best one. This turned out to be the VQGAN model, which allows visually consistent prostate scans to be generated from Gaussian noise. 

\paragraph{The next steps}\mbox{}\\
\indent The next action that may be pursued involves improving both the resolution and the dimensions of the scans. The enhancement in quality can be done by fine-tuning the parameters of the VQGAN model, with particular attention to the Autoencoder segment. A plausible method to accomplish this is by altering the codebook size and correspondingly adjusting the scan size within the latent space.

Due to the fact that scans exceeding dimensions of 128x128 could not be handled by the graphics card, this particular size was employed for the majority of the models. In circumstances where it is necessary to produce larger scans, one can utilize the DDP sharded technique described in section x. 

Nevertheless, in situations where this configuration either operates at an insufficient speed or experiences out of memory issues again, it is advisable to transition to a different computational system, such as an Athena supercomputer.

